{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tira in /usr/local/lib/python3.10/dist-packages (0.0.132)\n",
      "Requirement already satisfied: ir-datasets in /usr/local/lib/python3.10/dist-packages (0.5.5)\n",
      "Requirement already satisfied: python-terrier in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tira) (4.66.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tira) (2.1.3)\n",
      "Requirement already satisfied: docker==6.*,>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tira) (6.1.3)\n",
      "Requirement already satisfied: requests==2.*,>=2.26 in /usr/local/lib/python3.10/dist-packages (from tira) (2.31.0)\n",
      "Requirement already satisfied: packaging>=14.0 in /usr/local/lib/python3.10/dist-packages (from docker==6.*,>=6.0.0->tira) (23.2)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from docker==6.*,>=6.0.0->tira) (1.7.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker==6.*,>=6.0.0->tira) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.*,>=2.26->tira) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.*,>=2.26->tira) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.*,>=2.26->tira) (3.6)\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (2.6)\n",
      "Requirement already satisfied: ijson>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (3.2.3)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (4.12.2)\n",
      "Requirement already satisfied: lz4>=3.1.10 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (4.3.2)\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (0.1.6)\n",
      "Requirement already satisfied: pyautocorpus>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (0.1.12)\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (0.2.2)\n",
      "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (4.9.3)\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (0.2.3)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (1.26.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (6.0.1)\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (0.2.5)\n",
      "Requirement already satisfied: inscriptis>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (2.3.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.3.2)\n",
      "Requirement already satisfied: deprecated in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.2.14)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from python-terrier) (10.1.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.11.4)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.3.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (3.1.2)\n",
      "Requirement already satisfied: ir-measures>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.3.3)\n",
      "Requirement already satisfied: nptyping==1.4.4 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.4.4)\n",
      "Requirement already satisfied: pyjnius>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.6.1)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.3.7)\n",
      "Requirement already satisfied: matchpy in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.5.5)\n",
      "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.14.0)\n",
      "Requirement already satisfied: chest in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.2.3)\n",
      "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (from python-terrier) (3.2)\n",
      "Requirement already satisfied: pytrec-eval-terrier>=0.5.3 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.5.6)\n",
      "Requirement already satisfied: typish>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from nptyping==1.4.4->python-terrier) (1.9.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets) (2.5)\n",
      "Requirement already satisfied: cwl-eval>=1.0.10 in /usr/local/lib/python3.10/dist-packages (from ir-measures>=0.3.1->python-terrier) (1.0.12)\n",
      "Requirement already satisfied: cbor>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from trec-car-tools>=2.5.4->ir-datasets) (1.0.0)\n",
      "Requirement already satisfied: heapdict in /usr/local/lib/python3.10/dist-packages (from chest->python-terrier) (1.0.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->python-terrier) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->python-terrier) (2.1.3)\n",
      "Requirement already satisfied: multiset<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from matchpy->python-terrier) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->tira) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tira) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tira) (2023.3.post1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->python-terrier) (3.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels->python-terrier) (0.5.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels->python-terrier) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Nur benötigt für GoLab\n",
    "!pip3 install tira ir-datasets python-terrier nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "from tira.rest_api_client import Client\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "import pyterrier as pt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# PyTerrier initialisieren\n",
    "ensure_pyterrier_is_loaded()\n",
    "tira = Client()\n",
    "\n",
    "# PyTerrier starten\n",
    "if not pt.started():\n",
    "    pt.init()\n",
    "\n",
    "# NLTK SnowballStemmer initialisieren\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# Pandas Display-Einstellungen\n",
    "pd.set_option('display.max_colwidth', 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-sose-2024/ir-acl-anthology-20240504-training documents: 100%|██████████| 126958/126958 [02:41<00:00, 786.87it/s] \n"
     ]
    }
   ],
   "source": [
    "# Dataset von der TIRA Plattform abrufen\n",
    "pt_dataset = pt.get_dataset('irds:ir-lab-sose-2024/ir-acl-anthology-20240504-training')\n",
    "\n",
    "# Vorverarbeitung: SnowballStemmer auf den Text anwenden\n",
    "def stem_text(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "# Iterieren über den Corpus und Texte stemmen\n",
    "processed_corpus = []\n",
    "for doc in pt_dataset.get_corpus_iter():\n",
    "    doc_id = doc['docno']\n",
    "    text = doc['text']\n",
    "    stemmed_text = stem_text(text)\n",
    "    processed_corpus.append({'docno': doc_id, 'text': stemmed_text})\n",
    "\n",
    "# Konvertieren in DataFrame\n",
    "processed_corpus_df = pd.DataFrame(processed_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07:34:46.199 [ForkJoinPool-2-worker-3] WARN org.terrier.structures.indexing.Indexer - Adding an empty document to the index (2020.mir_conference-2020.1) - further warnings are suppressed\n",
      "07:34:53.732 [ForkJoinPool-2-worker-3] WARN org.terrier.structures.indexing.Indexer - Indexed 1 empty documents\n"
     ]
    }
   ],
   "source": [
    "# Index erstellen\n",
    "indexer = pt.IterDictIndexer(\"/tmp/index2\", overwrite=True, stemmer='none')  # Kein zusätzlicher Stemmer hier, da wir bereits gestemmt haben\n",
    "index_ref = indexer.index(processed_corpus)\n",
    "\n",
    "# Index laden\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "\n",
    "# BM25 Retrieval Modell initialisieren\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are multiple query fields available: ('text', 'title', 'query', 'description', 'narrative'). To use with pyterrier, provide variant or modify dataframe to add query column.\n"
     ]
    }
   ],
   "source": [
    "def stem_query_dataframe(query_df):\n",
    "    query_df['text'] = query_df['text'].apply(stem_text)\n",
    "    return query_df\n",
    "\n",
    "stemmed_topics_df = stem_query_dataframe(pt_dataset.get_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>query</th>\n",
       "      <th>description</th>\n",
       "      <th>narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>36009</td>\n",
       "      <td>T75-2025</td>\n",
       "      <td>0</td>\n",
       "      <td>21.580689</td>\n",
       "      <td>retriev system improv effect</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "      <td>What papers focus on improving the effectiveness of a retrieval system?</td>\n",
       "      <td>Relevant papers include research on what makes a retrieval system effective and what improves the effectiveness of a retrieval system. Papers that focus on improving something else or improving the effectiveness of a system that is not a retrieval system are not relevant.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>126778</td>\n",
       "      <td>1999.tois_journal-i</td>\n",
       "      <td>1</td>\n",
       "      <td>18.178801</td>\n",
       "      <td>retriev system improv effect</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "      <td>What papers focus on improving the effectiveness of a retrieval system?</td>\n",
       "      <td>Relevant papers include research on what makes a retrieval system effective and what improves the effectiveness of a retrieval system. Papers that focus on improving something else or improving the effectiveness of a system that is not a retrieval system are not relevant.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>74020</td>\n",
       "      <td>2008.ntcir_workshop</td>\n",
       "      <td>2</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>retriev system improv effect</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "      <td>What papers focus on improving the effectiveness of a retrieval system?</td>\n",
       "      <td>Relevant papers include research on what makes a retrieval system effective and what improves the effectiveness of a retrieval system. Papers that focus on improving something else or improving the effectiveness of a system that is not a retrieval system are not relevant.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1177</td>\n",
       "      <td>W18-5301</td>\n",
       "      <td>3</td>\n",
       "      <td>17.541705</td>\n",
       "      <td>retriev system improv effect</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "      <td>What papers focus on improving the effectiveness of a retrieval system?</td>\n",
       "      <td>Relevant papers include research on what makes a retrieval system effective and what improves the effectiveness of a retrieval system. Papers that focus on improving something else or improving the effectiveness of a system that is not a retrieval system are not relevant.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>82900</td>\n",
       "      <td>2013.sigirconf_conf</td>\n",
       "      <td>4</td>\n",
       "      <td>17.028760</td>\n",
       "      <td>retriev system improv effect</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "      <td>What papers focus on improving the effectiveness of a retrieval system?</td>\n",
       "      <td>Relevant papers include research on what makes a retrieval system effective and what improves the effectiveness of a retrieval system. Papers that focus on improving something else or improving the effectiveness of a system that is not a retrieval system are not relevant.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>92066</td>\n",
       "      <td>2005.ecir_conferenc</td>\n",
       "      <td>5</td>\n",
       "      <td>16.361147</td>\n",
       "      <td>retriev system improv effect</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "      <td>What papers focus on improving the effectiveness of a retrieval system?</td>\n",
       "      <td>Relevant papers include research on what makes a retrieval system effective and what improves the effectiveness of a retrieval system. Papers that focus on improving something else or improving the effectiveness of a system that is not a retrieval system are not relevant.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>80745</td>\n",
       "      <td>2008.sigirconf_conf</td>\n",
       "      <td>6</td>\n",
       "      <td>15.878637</td>\n",
       "      <td>retriev system improv effect</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "      <td>What papers focus on improving the effectiveness of a retrieval system?</td>\n",
       "      <td>Relevant papers include research on what makes a retrieval system effective and what improves the effectiveness of a retrieval system. Papers that focus on improving something else or improving the effectiveness of a system that is not a retrieval system are not relevant.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>76958</td>\n",
       "      <td>2013.dir_workshop-2</td>\n",
       "      <td>7</td>\n",
       "      <td>15.286855</td>\n",
       "      <td>retriev system improv effect</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "      <td>What papers focus on improving the effectiveness of a retrieval system?</td>\n",
       "      <td>Relevant papers include research on what makes a retrieval system effective and what improves the effectiveness of a retrieval system. Papers that focus on improving something else or improving the effectiveness of a system that is not a retrieval system are not relevant.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>90861</td>\n",
       "      <td>2021.ecir_conferenc</td>\n",
       "      <td>8</td>\n",
       "      <td>15.064785</td>\n",
       "      <td>retriev system improv effect</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "      <td>What papers focus on improving the effectiveness of a retrieval system?</td>\n",
       "      <td>Relevant papers include research on what makes a retrieval system effective and what improves the effectiveness of a retrieval system. Papers that focus on improving something else or improving the effectiveness of a system that is not a retrieval system are not relevant.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>29696</td>\n",
       "      <td>P07-2025</td>\n",
       "      <td>9</td>\n",
       "      <td>14.848132</td>\n",
       "      <td>retriev system improv effect</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "      <td>retrieval system improving effectiveness</td>\n",
       "      <td>What papers focus on improving the effectiveness of a retrieval system?</td>\n",
       "      <td>Relevant papers include research on what makes a retrieval system effective and what improves the effectiveness of a retrieval system. Papers that focus on improving something else or improving the effectiveness of a system that is not a retrieval system are not relevant.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid   docid                docno  rank      score  \\\n",
       "0  1   36009   T75-2025             0     21.580689   \n",
       "1  1   126778  1999.tois_journal-i  1     18.178801   \n",
       "2  1   74020   2008.ntcir_workshop  2     17.750000   \n",
       "3  1   1177    W18-5301             3     17.541705   \n",
       "4  1   82900   2013.sigirconf_conf  4     17.028760   \n",
       "5  1   92066   2005.ecir_conferenc  5     16.361147   \n",
       "6  1   80745   2008.sigirconf_conf  6     15.878637   \n",
       "7  1   76958   2013.dir_workshop-2  7     15.286855   \n",
       "8  1   90861   2021.ecir_conferenc  8     15.064785   \n",
       "9  1   29696   P07-2025             9     14.848132   \n",
       "\n",
       "                           text                                     title  \\\n",
       "0  retriev system improv effect  retrieval system improving effectiveness   \n",
       "1  retriev system improv effect  retrieval system improving effectiveness   \n",
       "2  retriev system improv effect  retrieval system improving effectiveness   \n",
       "3  retriev system improv effect  retrieval system improving effectiveness   \n",
       "4  retriev system improv effect  retrieval system improving effectiveness   \n",
       "5  retriev system improv effect  retrieval system improving effectiveness   \n",
       "6  retriev system improv effect  retrieval system improving effectiveness   \n",
       "7  retriev system improv effect  retrieval system improving effectiveness   \n",
       "8  retriev system improv effect  retrieval system improving effectiveness   \n",
       "9  retriev system improv effect  retrieval system improving effectiveness   \n",
       "\n",
       "                                      query  \\\n",
       "0  retrieval system improving effectiveness   \n",
       "1  retrieval system improving effectiveness   \n",
       "2  retrieval system improving effectiveness   \n",
       "3  retrieval system improving effectiveness   \n",
       "4  retrieval system improving effectiveness   \n",
       "5  retrieval system improving effectiveness   \n",
       "6  retrieval system improving effectiveness   \n",
       "7  retrieval system improving effectiveness   \n",
       "8  retrieval system improving effectiveness   \n",
       "9  retrieval system improving effectiveness   \n",
       "\n",
       "                                                               description  \\\n",
       "0  What papers focus on improving the effectiveness of a retrieval system?   \n",
       "1  What papers focus on improving the effectiveness of a retrieval system?   \n",
       "2  What papers focus on improving the effectiveness of a retrieval system?   \n",
       "3  What papers focus on improving the effectiveness of a retrieval system?   \n",
       "4  What papers focus on improving the effectiveness of a retrieval system?   \n",
       "5  What papers focus on improving the effectiveness of a retrieval system?   \n",
       "6  What papers focus on improving the effectiveness of a retrieval system?   \n",
       "7  What papers focus on improving the effectiveness of a retrieval system?   \n",
       "8  What papers focus on improving the effectiveness of a retrieval system?   \n",
       "9  What papers focus on improving the effectiveness of a retrieval system?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                          narrative  \n",
       "0  Relevant papers include research on what makes a retrieval system effective and what improves the effectiveness of a retrieval system. Papers that focus on improving something else or improving the effectiveness of a system that is not a retrieval system are not relevant.  \n",
       "1  Relevant papers include research on what makes a retrieval system effective and what improves the effectiveness of a retrieval system. Papers that focus on improving something else or improving the effectiveness of a system that is not a retrieval system are not relevant.  \n",
       "2  Relevant papers include research on what makes a retrieval system effective and what improves the effectiveness of a retrieval system. Papers that focus on improving something else or improving the effectiveness of a system that is not a retrieval system are not relevant.  \n",
       "3  Relevant papers include research on what makes a retrieval system effective and what improves the effectiveness of a retrieval system. Papers that focus on improving something else or improving the effectiveness of a system that is not a retrieval system are not relevant.  \n",
       "4  Relevant papers include research on what makes a retrieval system effective and what improves the effectiveness of a retrieval system. Papers that focus on improving something else or improving the effectiveness of a system that is not a retrieval system are not relevant.  \n",
       "5  Relevant papers include research on what makes a retrieval system effective and what improves the effectiveness of a retrieval system. Papers that focus on improving something else or improving the effectiveness of a system that is not a retrieval system are not relevant.  \n",
       "6  Relevant papers include research on what makes a retrieval system effective and what improves the effectiveness of a retrieval system. Papers that focus on improving something else or improving the effectiveness of a system that is not a retrieval system are not relevant.  \n",
       "7  Relevant papers include research on what makes a retrieval system effective and what improves the effectiveness of a retrieval system. Papers that focus on improving something else or improving the effectiveness of a system that is not a retrieval system are not relevant.  \n",
       "8  Relevant papers include research on what makes a retrieval system effective and what improves the effectiveness of a retrieval system. Papers that focus on improving something else or improving the effectiveness of a system that is not a retrieval system are not relevant.  \n",
       "9  Relevant papers include research on what makes a retrieval system effective and what improves the effectiveness of a retrieval system. Papers that focus on improving something else or improving the effectiveness of a system that is not a retrieval system are not relevant.  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('Now we do the retrieval...')\n",
    "run = bm25(stemmed_topics_df)\n",
    "\n",
    "#print('Done. Here are the first 10 entries of the run')\n",
    "run.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"../../runs\".\n",
      "Done. run file is stored under \"../../runs/run.txt\".\n"
     ]
    }
   ],
   "source": [
    "# Output runfile für das Deployment auf TIRA\n",
    "persist_and_normalize_run(run, system_name='bm25-baseline', default_output='../../runs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gestemmte Abfrage: retriev system improv effect\n"
     ]
    }
   ],
   "source": [
    "# Einzelne gestemmte Abfrage\n",
    "query = \"retrieval system improving effectiveness\"\n",
    "stemmed_query = stem_text(query)\n",
    "print(f\"Gestemmte Abfrage: {stemmed_query}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    qid   docid                docno  rank      score  \\\n",
      "0    1   94858   2004.cikm_conferenc  0     16.232194   \n",
      "1    1   125137  1989.ipm_journal-ir  1     15.678307   \n",
      "2    1   5868    W05-0704             2     14.409583   \n",
      "3    1   94415   2008.cikm_conferenc  3     14.341223   \n",
      "4    1   125817  2005.ipm_journal-ir  4     14.093883   \n",
      "..  ..      ...                  ... ..           ...   \n",
      "995  1   80937   2008.sigirconf_conf  995   9.058766    \n",
      "996  1   80908   2008.sigirconf_conf  996   9.055515    \n",
      "997  1   111407  2005.trec_conferenc  997   9.055515    \n",
      "998  1   126143  2015.tois_journal-i  998   9.051541    \n",
      "999  1   83446   1997.sigirconf_conf  999   9.051440    \n",
      "\n",
      "                            query  \n",
      "0    retriev system improv effect  \n",
      "1    retriev system improv effect  \n",
      "2    retriev system improv effect  \n",
      "3    retriev system improv effect  \n",
      "4    retriev system improv effect  \n",
      "..                            ...  \n",
      "995  retriev system improv effect  \n",
      "996  retriev system improv effect  \n",
      "997  retriev system improv effect  \n",
      "998  retriev system improv effect  \n",
      "999  retriev system improv effect  \n",
      "\n",
      "[1000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Manuelle Suche\n",
    "results = bm25.search(stemmed_query)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Dokumente im Index: 126958\n"
     ]
    }
   ],
   "source": [
    "# Prüfen wir die Dokumentanzahl im Index\n",
    "print(f\"Anzahl der Dokumente im Index: {index.getCollectionStatistics().getNumberOfDocuments()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docno</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O02-2002</td>\n",
       "      <td>a studi on word similar use context vector model there is a need to measur word similar when process natur languages, especi when use generalization, classification, or exampl -base approaches. usually, measur of similar between two word are defin accord to the distanc between their semant class in a semant taxonomi . the taxonomi approach are more or less semant -base that do not consid syntact similarit ies. however, in real applications, both semant and syntact similar are requir and weight differently. word similar base on context vector is a mixtur of syntact and semant similarit ies. in this paper, we propos use onli syntact relat co-occurr as context vector and adopt inform theoret model to solv the problem of data spars and characterist precision. the probabilist distribut of co-occurr context featur is deriv by pars the contextu environ of each word , and all the context featur are adjust accord to their idf (invers document frequency) values. the agglom cluster algorithm is appli to group similar word accord to their similar values. it turn out that word with similar syntact categori and semant class are group together.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L02-1310</td>\n",
       "      <td>bootstrap larg sens tag corpora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R13-1042</td>\n",
       "      <td>headerless, quoteless, but not hopeless? use pairwis email classif to disentangl email thread thread disentangl is the task of separ out convers whose thread structur is implicit, distorted, or lost. in this paper, we perform email thread disentangl through pairwis classification, use text similar measur on non-quot text in emails. we show that i) content text similar metric outperform style and structur text similar metric in both a class-balanc and class-imbalanc setting, and ii) although featur perform is depend on the semant similar of the corpus, content featur are still effect even when control for semant similarity. we make avail the enron thread corpus, a newly-extract corpus of 70,178 multiemail thread with email from the enron email corpus.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W05-0819</td>\n",
       "      <td>align word in {e}nglish-{h}indi parallel corpora in this paper, we describ a word align algorithm for english-hindi parallel data. the system was develop to particip in the share task on word align for languag with scarc resourc at the acl 2005 workshop, on \"build and use parallel texts: data driven machin translat and beyond\". our word align algorithm is base on a hybrid method which perform local word group on hindi sentenc and use other method such as dictionari lookup, transliter similarity, expect english word and nearest align neighbours. we train our system on the train data provid to obtain a list of name entiti and cognat and to collect rule for local word group in hindi sentences. the system score 77.03% precis and 60.68% recal on the share task unseen test data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L02-1309</td>\n",
       "      <td>propos of a very-large-corpus acquisit method by cell-form registr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      docno  \\\n",
       "0  O02-2002   \n",
       "1  L02-1310   \n",
       "2  R13-1042   \n",
       "3  W05-0819   \n",
       "4  L02-1309   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          text  \n",
       "0  a studi on word similar use context vector model there is a need to measur word similar when process natur languages, especi when use generalization, classification, or exampl -base approaches. usually, measur of similar between two word are defin accord to the distanc between their semant class in a semant taxonomi . the taxonomi approach are more or less semant -base that do not consid syntact similarit ies. however, in real applications, both semant and syntact similar are requir and weight differently. word similar base on context vector is a mixtur of syntact and semant similarit ies. in this paper, we propos use onli syntact relat co-occurr as context vector and adopt inform theoret model to solv the problem of data spars and characterist precision. the probabilist distribut of co-occurr context featur is deriv by pars the contextu environ of each word , and all the context featur are adjust accord to their idf (invers document frequency) values. the agglom cluster algorithm is appli to group similar word accord to their similar values. it turn out that word with similar syntact categori and semant class are group together.  \n",
       "1  bootstrap larg sens tag corpora                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "2  headerless, quoteless, but not hopeless? use pairwis email classif to disentangl email thread thread disentangl is the task of separ out convers whose thread structur is implicit, distorted, or lost. in this paper, we perform email thread disentangl through pairwis classification, use text similar measur on non-quot text in emails. we show that i) content text similar metric outperform style and structur text similar metric in both a class-balanc and class-imbalanc setting, and ii) although featur perform is depend on the semant similar of the corpus, content featur are still effect even when control for semant similarity. we make avail the enron thread corpus, a newly-extract corpus of 70,178 multiemail thread with email from the enron email corpus.                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "3  align word in {e}nglish-{h}indi parallel corpora in this paper, we describ a word align algorithm for english-hindi parallel data. the system was develop to particip in the share task on word align for languag with scarc resourc at the acl 2005 workshop, on \"build and use parallel texts: data driven machin translat and beyond\". our word align algorithm is base on a hybrid method which perform local word group on hindi sentenc and use other method such as dictionari lookup, transliter similarity, expect english word and nearest align neighbours. we train our system on the train data provid to obtain a list of name entiti and cognat and to collect rule for local word group in hindi sentences. the system score 77.03% precis and 60.68% recal on the share task unseen test data.                                                                                                                                                                                                                                                                                                                                                                              \n",
       "4  propos of a very-large-corpus acquisit method by cell-form registr                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_corpus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>recip_rank</th>\n",
       "      <th>P_1000</th>\n",
       "      <th>ndcg_cut_5</th>\n",
       "      <th>map +</th>\n",
       "      <th>map -</th>\n",
       "      <th>map p-value</th>\n",
       "      <th>recip_rank +</th>\n",
       "      <th>recip_rank -</th>\n",
       "      <th>recip_rank p-value</th>\n",
       "      <th>P_1000 +</th>\n",
       "      <th>P_1000 -</th>\n",
       "      <th>P_1000 p-value</th>\n",
       "      <th>ndcg_cut_5 +</th>\n",
       "      <th>ndcg_cut_5 -</th>\n",
       "      <th>ndcg_cut_5 p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  map  recip_rank  P_1000  ndcg_cut_5 map + map - map p-value  \\\n",
       "0  BM25  0.0  0.0         0.0     0.0         None  None  None         \n",
       "\n",
       "  recip_rank + recip_rank - recip_rank p-value P_1000 + P_1000 -  \\\n",
       "0  None         None         None               None     None      \n",
       "\n",
       "  P_1000 p-value ndcg_cut_5 + ndcg_cut_5 - ndcg_cut_5 p-value  \n",
       "0  None           None         None         None               "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Localtest\n",
    "pt.Experiment(\n",
    "    [bm25], \n",
    "    stemmed_topics_df, \n",
    "    pt_dataset.get_qrels(), \n",
    "    eval_metrics=['P_1000', 'map', 'recip_rank', 'ndcg_cut_5'],\n",
    "    names=['BM25'],\n",
    "    baseline=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>label</th>\n",
       "      <th>iteration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2005.ipm_journal-ir0volumeA41A1.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019.tois_journal-ir0volumeA37A1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2008.sigirconf_conference-2008.127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2015.ipm_journal-ir0volumeA51A5.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2008.tois_journal-ir0volumeA27A1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>18</td>\n",
       "      <td>1985.jasis_journal-ir0volumeA36A3.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2619</th>\n",
       "      <td>18</td>\n",
       "      <td>2010.wwwconf_conference-2010.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2620</th>\n",
       "      <td>18</td>\n",
       "      <td>2011.ntcir_workshop-2011evia.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621</th>\n",
       "      <td>18</td>\n",
       "      <td>1988.ipm_journal-ir0volumeA24A3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>18</td>\n",
       "      <td>2010.airs_conference-2010.12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2623 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     qid                                docno  label iteration\n",
       "0     1   2005.ipm_journal-ir0volumeA41A1.7    1      0       \n",
       "1     1   2019.tois_journal-ir0volumeA37A1.2   1      0       \n",
       "2     1   2008.sigirconf_conference-2008.127   1      0       \n",
       "3     1   2015.ipm_journal-ir0volumeA51A5.7    0      0       \n",
       "4     1   2008.tois_journal-ir0volumeA27A1.1   0      0       \n",
       "...  ..                                  ...  ..     ..       \n",
       "2618  18  1985.jasis_journal-ir0volumeA36A3.9  0      0       \n",
       "2619  18  2010.wwwconf_conference-2010.11      1      0       \n",
       "2620  18  2011.ntcir_workshop-2011evia.3       0      0       \n",
       "2621  18  1988.ipm_journal-ir0volumeA24A3.1    0      0       \n",
       "2622  18  2010.airs_conference-2010.12         0      0       \n",
       "\n",
       "[2623 rows x 4 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_dataset.get_qrels()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
